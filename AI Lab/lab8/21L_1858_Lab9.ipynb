{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Task 1:**"
      ],
      "metadata": {
        "id": "yLzNTKbeu_l_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fashion mnist"
      ],
      "metadata": {
        "id": "msUeoJPUvD1U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quJgp4TvueZC",
        "outputId": "53ba88c9-5d0a-4577-a5b3-3bd7e7e8a65a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               200960    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 235146 (918.54 KB)\n",
            "Trainable params: 235146 (918.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "1500/1500 [==============================] - 11s 7ms/step - loss: 0.4924 - accuracy: 0.8220 - val_loss: 0.3965 - val_accuracy: 0.8558\n",
            "Epoch 2/25\n",
            "1500/1500 [==============================] - 10s 6ms/step - loss: 0.3699 - accuracy: 0.8648 - val_loss: 0.3771 - val_accuracy: 0.8641\n",
            "Epoch 3/25\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.3329 - accuracy: 0.8772 - val_loss: 0.3401 - val_accuracy: 0.8770\n",
            "Epoch 4/25\n",
            "1500/1500 [==============================] - 10s 6ms/step - loss: 0.3064 - accuracy: 0.8856 - val_loss: 0.3312 - val_accuracy: 0.8786\n",
            "Epoch 5/25\n",
            "1500/1500 [==============================] - 10s 6ms/step - loss: 0.2893 - accuracy: 0.8924 - val_loss: 0.3120 - val_accuracy: 0.8880\n",
            "Epoch 6/25\n",
            "1500/1500 [==============================] - 10s 7ms/step - loss: 0.2709 - accuracy: 0.8986 - val_loss: 0.3449 - val_accuracy: 0.8764\n",
            "Epoch 7/25\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2600 - accuracy: 0.9024 - val_loss: 0.3325 - val_accuracy: 0.8810\n",
            "Epoch 8/25\n",
            "1500/1500 [==============================] - 10s 6ms/step - loss: 0.2483 - accuracy: 0.9063 - val_loss: 0.3195 - val_accuracy: 0.8837\n",
            "Epoch 9/25\n",
            "1500/1500 [==============================] - 10s 7ms/step - loss: 0.2396 - accuracy: 0.9093 - val_loss: 0.3240 - val_accuracy: 0.8814\n",
            "Epoch 10/25\n",
            "1500/1500 [==============================] - 11s 8ms/step - loss: 0.2274 - accuracy: 0.9141 - val_loss: 0.3251 - val_accuracy: 0.8881\n",
            "Epoch 11/25\n",
            "1500/1500 [==============================] - 13s 9ms/step - loss: 0.2187 - accuracy: 0.9165 - val_loss: 0.3190 - val_accuracy: 0.8916\n",
            "Epoch 12/25\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2102 - accuracy: 0.9193 - val_loss: 0.3462 - val_accuracy: 0.8777\n",
            "Epoch 13/25\n",
            "1500/1500 [==============================] - 10s 7ms/step - loss: 0.2015 - accuracy: 0.9246 - val_loss: 0.3201 - val_accuracy: 0.8964\n",
            "Epoch 14/25\n",
            "1500/1500 [==============================] - 10s 7ms/step - loss: 0.1947 - accuracy: 0.9255 - val_loss: 0.3275 - val_accuracy: 0.8938\n",
            "Epoch 15/25\n",
            "1500/1500 [==============================] - 10s 7ms/step - loss: 0.1905 - accuracy: 0.9278 - val_loss: 0.3435 - val_accuracy: 0.8900\n",
            "Epoch 16/25\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1813 - accuracy: 0.9310 - val_loss: 0.3660 - val_accuracy: 0.8905\n",
            "Epoch 17/25\n",
            "1500/1500 [==============================] - 11s 8ms/step - loss: 0.1762 - accuracy: 0.9338 - val_loss: 0.3367 - val_accuracy: 0.8978\n",
            "Epoch 18/25\n",
            "1500/1500 [==============================] - 10s 7ms/step - loss: 0.1679 - accuracy: 0.9363 - val_loss: 0.3615 - val_accuracy: 0.8903\n",
            "Epoch 19/25\n",
            "1500/1500 [==============================] - 10s 7ms/step - loss: 0.1657 - accuracy: 0.9366 - val_loss: 0.3733 - val_accuracy: 0.8912\n",
            "Epoch 20/25\n",
            "1500/1500 [==============================] - 10s 7ms/step - loss: 0.1609 - accuracy: 0.9389 - val_loss: 0.3652 - val_accuracy: 0.8958\n",
            "Epoch 21/25\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1531 - accuracy: 0.9409 - val_loss: 0.4009 - val_accuracy: 0.8891\n",
            "Epoch 22/25\n",
            "1500/1500 [==============================] - 10s 7ms/step - loss: 0.1499 - accuracy: 0.9430 - val_loss: 0.4248 - val_accuracy: 0.8876\n",
            "Epoch 23/25\n",
            "1500/1500 [==============================] - 11s 7ms/step - loss: 0.1459 - accuracy: 0.9436 - val_loss: 0.3872 - val_accuracy: 0.8904\n",
            "Epoch 24/25\n",
            "1500/1500 [==============================] - 10s 7ms/step - loss: 0.1432 - accuracy: 0.9455 - val_loss: 0.4065 - val_accuracy: 0.8882\n",
            "Epoch 25/25\n",
            "1500/1500 [==============================] - 10s 6ms/step - loss: 0.1337 - accuracy: 0.9486 - val_loss: 0.3916 - val_accuracy: 0.8942\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4343 - accuracy: 0.8896\n",
            "Test Loss: 0.43426182866096497\n",
            "Test Accuracy: 0.8895999789237976\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "# Load Fashion MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# Preprocessing: Scale the pixel values to the range of 0 to 1\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# Model Building\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "\n",
        "# Create the model\n",
        "model_fashion = Sequential()\n",
        "\n",
        "# Reshape into 1-dimensional data\n",
        "model_fashion.add(Flatten(input_shape=(28, 28)))\n",
        "\n",
        "# Dense layer 1\n",
        "model_fashion.add(Dense(256, activation='relu'))\n",
        "\n",
        "# Dense layer 2\n",
        "model_fashion.add(Dense(128, activation='relu'))\n",
        "\n",
        "# Output layer\n",
        "model_fashion.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Model summary\n",
        "model_fashion.summary()\n",
        "\n",
        "# Compile the model\n",
        "model_fashion.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                       optimizer=\"adam\",\n",
        "                       metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model\n",
        "history_fashion = model_fashion.fit(X_train, y_train, epochs=25, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss_fashion, test_accuracy_fashion = model_fashion.evaluate(X_test, y_test)\n",
        "print('Test Loss:', test_loss_fashion)\n",
        "print('Test Accuracy:', test_accuracy_fashion)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "cifar10"
      ],
      "metadata": {
        "id": "BdTNlVXQvHx8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Preprocessing: Scale the pixel values to the range of 0 to 1\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# Model Building\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "\n",
        "# Create the model\n",
        "model_cifar10 = Sequential()\n",
        "\n",
        "# Reshape into 1-dimensional data\n",
        "model_cifar10.add(Flatten(input_shape=(32, 32, 3)))\n",
        "\n",
        "# Dense layer 1\n",
        "model_cifar10.add(Dense(256, activation='relu'))\n",
        "\n",
        "# Dense layer 2\n",
        "model_cifar10.add(Dense(128, activation='relu'))\n",
        "\n",
        "# Output layer\n",
        "model_cifar10.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Model summary\n",
        "model_cifar10.summary()\n",
        "\n",
        "# Compile the model\n",
        "model_cifar10.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                      optimizer=\"adam\",\n",
        "                      metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model\n",
        "history_cifar10 = model_cifar10.fit(X_train, y_train, epochs=25, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss_cifar10, test_accuracy_cifar10 = model_cifar10.evaluate(X_test, y_test)\n",
        "print('Test Loss:', test_loss_cifar10)\n",
        "print('Test Accuracy:', test_accuracy_cifar10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEx7WRTou5AR",
        "outputId": "f7604995-62b5-4c65-8c14-1367d980a0fd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 2s 0us/step\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 256)               786688    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 820874 (3.13 MB)\n",
            "Trainable params: 820874 (3.13 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "1250/1250 [==============================] - 19s 15ms/step - loss: 1.8906 - accuracy: 0.3169 - val_loss: 1.8335 - val_accuracy: 0.3407\n",
            "Epoch 2/25\n",
            "1250/1250 [==============================] - 17s 14ms/step - loss: 1.7121 - accuracy: 0.3855 - val_loss: 1.6903 - val_accuracy: 0.3997\n",
            "Epoch 3/25\n",
            "1250/1250 [==============================] - 17s 14ms/step - loss: 1.6263 - accuracy: 0.4178 - val_loss: 1.6171 - val_accuracy: 0.4213\n",
            "Epoch 4/25\n",
            "1250/1250 [==============================] - 18s 14ms/step - loss: 1.5762 - accuracy: 0.4340 - val_loss: 1.7794 - val_accuracy: 0.3779\n",
            "Epoch 5/25\n",
            "1250/1250 [==============================] - 18s 14ms/step - loss: 1.5403 - accuracy: 0.4480 - val_loss: 1.5961 - val_accuracy: 0.4348\n",
            "Epoch 6/25\n",
            "1250/1250 [==============================] - 17s 13ms/step - loss: 1.5052 - accuracy: 0.4610 - val_loss: 1.5685 - val_accuracy: 0.4433\n",
            "Epoch 7/25\n",
            "1250/1250 [==============================] - 18s 14ms/step - loss: 1.4819 - accuracy: 0.4687 - val_loss: 1.5309 - val_accuracy: 0.4629\n",
            "Epoch 8/25\n",
            "1250/1250 [==============================] - 17s 13ms/step - loss: 1.4544 - accuracy: 0.4818 - val_loss: 1.5652 - val_accuracy: 0.4477\n",
            "Epoch 9/25\n",
            "1250/1250 [==============================] - 17s 13ms/step - loss: 1.4390 - accuracy: 0.4885 - val_loss: 1.5110 - val_accuracy: 0.4670\n",
            "Epoch 10/25\n",
            "1250/1250 [==============================] - 18s 15ms/step - loss: 1.4178 - accuracy: 0.4938 - val_loss: 1.4957 - val_accuracy: 0.4771\n",
            "Epoch 11/25\n",
            "1250/1250 [==============================] - 17s 13ms/step - loss: 1.4062 - accuracy: 0.4994 - val_loss: 1.5194 - val_accuracy: 0.4632\n",
            "Epoch 12/25\n",
            "1250/1250 [==============================] - 17s 13ms/step - loss: 1.3850 - accuracy: 0.5042 - val_loss: 1.5142 - val_accuracy: 0.4714\n",
            "Epoch 13/25\n",
            "1250/1250 [==============================] - 18s 15ms/step - loss: 1.3752 - accuracy: 0.5087 - val_loss: 1.5281 - val_accuracy: 0.4649\n",
            "Epoch 14/25\n",
            "1250/1250 [==============================] - 17s 13ms/step - loss: 1.3579 - accuracy: 0.5137 - val_loss: 1.5225 - val_accuracy: 0.4686\n",
            "Epoch 15/25\n",
            "1250/1250 [==============================] - 17s 14ms/step - loss: 1.3493 - accuracy: 0.5175 - val_loss: 1.4827 - val_accuracy: 0.4788\n",
            "Epoch 16/25\n",
            "1250/1250 [==============================] - 18s 15ms/step - loss: 1.3339 - accuracy: 0.5213 - val_loss: 1.5233 - val_accuracy: 0.4788\n",
            "Epoch 17/25\n",
            "1250/1250 [==============================] - 17s 14ms/step - loss: 1.3218 - accuracy: 0.5268 - val_loss: 1.4953 - val_accuracy: 0.4774\n",
            "Epoch 18/25\n",
            "1250/1250 [==============================] - 17s 13ms/step - loss: 1.3125 - accuracy: 0.5303 - val_loss: 1.4842 - val_accuracy: 0.4888\n",
            "Epoch 19/25\n",
            "1250/1250 [==============================] - 20s 16ms/step - loss: 1.3008 - accuracy: 0.5359 - val_loss: 1.5092 - val_accuracy: 0.4800\n",
            "Epoch 20/25\n",
            "1250/1250 [==============================] - 17s 13ms/step - loss: 1.2930 - accuracy: 0.5400 - val_loss: 1.5082 - val_accuracy: 0.4763\n",
            "Epoch 21/25\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 1.2855 - accuracy: 0.5416 - val_loss: 1.5614 - val_accuracy: 0.4670\n",
            "Epoch 22/25\n",
            "1250/1250 [==============================] - 18s 15ms/step - loss: 1.2765 - accuracy: 0.5430 - val_loss: 1.5010 - val_accuracy: 0.4850\n",
            "Epoch 23/25\n",
            "1250/1250 [==============================] - 17s 13ms/step - loss: 1.2650 - accuracy: 0.5467 - val_loss: 1.5095 - val_accuracy: 0.4848\n",
            "Epoch 24/25\n",
            "1250/1250 [==============================] - 17s 14ms/step - loss: 1.2619 - accuracy: 0.5498 - val_loss: 1.4894 - val_accuracy: 0.4861\n",
            "Epoch 25/25\n",
            "1250/1250 [==============================] - 22s 18ms/step - loss: 1.2522 - accuracy: 0.5520 - val_loss: 1.5008 - val_accuracy: 0.4846\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 1.4776 - accuracy: 0.4851\n",
            "Test Loss: 1.4775502681732178\n",
            "Test Accuracy: 0.48510000109672546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "cifar100"
      ],
      "metadata": {
        "id": "w9XAoMdGvKPy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import cifar100\n",
        "\n",
        "# Load CIFAR-100 dataset\n",
        "(X_train, y_train), (X_test, y_test) = cifar100.load_data(label_mode='fine')\n",
        "\n",
        "# Preprocessing: Scale the pixel values to the range of 0 to 1\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# Model Building\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "\n",
        "# Create the model\n",
        "model_cifar100 = Sequential()\n",
        "\n",
        "# Reshape into 1-dimensional data\n",
        "model_cifar100.add(Flatten(input_shape=(32, 32, 3)))\n",
        "\n",
        "# Dense layer 1\n",
        "model_cifar100.add(Dense(256, activation='relu'))\n",
        "\n",
        "# Dense layer 2\n",
        "model_cifar100.add(Dense(128, activation='relu'))\n",
        "\n",
        "# Output layer\n",
        "model_cifar100.add(Dense(100, activation='softmax'))\n",
        "\n",
        "# Model summary\n",
        "model_cifar100.summary()\n",
        "\n",
        "# Compile the model\n",
        "model_cifar100.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                       optimizer=\"adam\",\n",
        "                       metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model\n",
        "history_cifar100 = model_cifar100.fit(X_train, y_train, epochs=25, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss_cifar100, test_accuracy_cifar100 = model_cifar100.evaluate(X_test, y_test)\n",
        "print('Test Loss:', test_loss_cifar100)\n",
        "print('Test Accuracy:', test_accuracy_cifar100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ah4v7x9au7hJ",
        "outputId": "7df6dae9-3b6c-40a7-c648-360fcc8b1c1a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169001437/169001437 [==============================] - 3s 0us/step\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_2 (Flatten)         (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 256)               786688    \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 100)               12900     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 832484 (3.18 MB)\n",
            "Trainable params: 832484 (3.18 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "1250/1250 [==============================] - 18s 14ms/step - loss: 4.1392 - accuracy: 0.0684 - val_loss: 3.8848 - val_accuracy: 0.1034\n",
            "Epoch 2/25\n",
            "1250/1250 [==============================] - 17s 13ms/step - loss: 3.7553 - accuracy: 0.1258 - val_loss: 3.7154 - val_accuracy: 0.1351\n",
            "Epoch 3/25\n",
            "1250/1250 [==============================] - 18s 14ms/step - loss: 3.6045 - accuracy: 0.1492 - val_loss: 3.6232 - val_accuracy: 0.1496\n",
            "Epoch 4/25\n",
            "1250/1250 [==============================] - 17s 14ms/step - loss: 3.5179 - accuracy: 0.1660 - val_loss: 3.5534 - val_accuracy: 0.1680\n",
            "Epoch 5/25\n",
            "1250/1250 [==============================] - 17s 13ms/step - loss: 3.4437 - accuracy: 0.1770 - val_loss: 3.5162 - val_accuracy: 0.1721\n",
            "Epoch 6/25\n",
            "1250/1250 [==============================] - 18s 14ms/step - loss: 3.3883 - accuracy: 0.1882 - val_loss: 3.5422 - val_accuracy: 0.1657\n",
            "Epoch 7/25\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 3.3406 - accuracy: 0.1969 - val_loss: 3.4405 - val_accuracy: 0.1851\n",
            "Epoch 8/25\n",
            "1250/1250 [==============================] - 18s 14ms/step - loss: 3.2961 - accuracy: 0.2060 - val_loss: 3.4287 - val_accuracy: 0.1859\n",
            "Epoch 9/25\n",
            "1250/1250 [==============================] - 19s 15ms/step - loss: 3.2634 - accuracy: 0.2096 - val_loss: 3.4571 - val_accuracy: 0.1887\n",
            "Epoch 10/25\n",
            "1250/1250 [==============================] - 18s 15ms/step - loss: 3.2324 - accuracy: 0.2146 - val_loss: 3.4074 - val_accuracy: 0.1994\n",
            "Epoch 11/25\n",
            "1250/1250 [==============================] - 19s 15ms/step - loss: 3.1999 - accuracy: 0.2227 - val_loss: 3.4120 - val_accuracy: 0.1945\n",
            "Epoch 12/25\n",
            "1250/1250 [==============================] - 18s 14ms/step - loss: 3.1797 - accuracy: 0.2247 - val_loss: 3.4106 - val_accuracy: 0.1991\n",
            "Epoch 13/25\n",
            "1250/1250 [==============================] - 18s 14ms/step - loss: 3.1577 - accuracy: 0.2280 - val_loss: 3.4046 - val_accuracy: 0.2003\n",
            "Epoch 14/25\n",
            "1250/1250 [==============================] - 18s 14ms/step - loss: 3.1363 - accuracy: 0.2320 - val_loss: 3.3988 - val_accuracy: 0.1962\n",
            "Epoch 15/25\n",
            "1250/1250 [==============================] - 17s 14ms/step - loss: 3.1146 - accuracy: 0.2377 - val_loss: 3.4324 - val_accuracy: 0.2019\n",
            "Epoch 16/25\n",
            "1250/1250 [==============================] - 17s 14ms/step - loss: 3.1021 - accuracy: 0.2360 - val_loss: 3.4421 - val_accuracy: 0.1940\n",
            "Epoch 17/25\n",
            "1250/1250 [==============================] - 19s 15ms/step - loss: 3.0863 - accuracy: 0.2400 - val_loss: 3.3748 - val_accuracy: 0.2088\n",
            "Epoch 18/25\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 3.0731 - accuracy: 0.2425 - val_loss: 3.3979 - val_accuracy: 0.2058\n",
            "Epoch 19/25\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 3.0571 - accuracy: 0.2436 - val_loss: 3.4158 - val_accuracy: 0.2020\n",
            "Epoch 20/25\n",
            "1250/1250 [==============================] - 18s 15ms/step - loss: 3.0484 - accuracy: 0.2475 - val_loss: 3.4209 - val_accuracy: 0.2032\n",
            "Epoch 21/25\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 3.0319 - accuracy: 0.2514 - val_loss: 3.4597 - val_accuracy: 0.1962\n",
            "Epoch 22/25\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 3.0181 - accuracy: 0.2508 - val_loss: 3.4478 - val_accuracy: 0.2087\n",
            "Epoch 23/25\n",
            "1250/1250 [==============================] - 17s 13ms/step - loss: 3.0082 - accuracy: 0.2548 - val_loss: 3.4078 - val_accuracy: 0.2080\n",
            "Epoch 24/25\n",
            "1250/1250 [==============================] - 18s 14ms/step - loss: 2.9987 - accuracy: 0.2547 - val_loss: 3.4994 - val_accuracy: 0.1971\n",
            "Epoch 25/25\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 2.9954 - accuracy: 0.2598 - val_loss: 3.4310 - val_accuracy: 0.2093\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 3.4368 - accuracy: 0.2082\n",
            "Test Loss: 3.4368484020233154\n",
            "Test Accuracy: 0.20819999277591705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2:**"
      ],
      "metadata": {
        "id": "0NaqJEybTzdn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def initial_population(population_size, specific_solution=None):\n",
        "    population = []\n",
        "    if specific_solution:\n",
        "        population.append(specific_solution)\n",
        "        remaining_population_size = population_size - 1\n",
        "    else:\n",
        "        remaining_population_size = population_size\n",
        "\n",
        "    population.extend([[random.randint(0, 7) for _ in range(8)] for _ in range(remaining_population_size)])\n",
        "    return population\n",
        "\n",
        "def fitness(solution):\n",
        "    attacks = 0\n",
        "    for i in range(8):\n",
        "        for j in range(i + 1, 8):\n",
        "            if solution[i] == solution[j] or abs(i - j) == abs(solution[i] - solution[j]):\n",
        "                attacks += 1\n",
        "    return 28 - attacks  # Maximum fitness is 28 (no attacks)\n",
        "\n",
        "def selection(population, fitness_scores):\n",
        "    return random.choices(population, weights=fitness_scores, k=2)\n",
        "\n",
        "def crossover(parent1, parent2):\n",
        "    crossover_point = random.randint(1, 6)\n",
        "    child = parent1[:crossover_point] + parent2[crossover_point:]\n",
        "    return child\n",
        "\n",
        "def mutate(solution, mutation_rate):\n",
        "    if random.random() < mutation_rate:\n",
        "        index = random.randint(0, 7)\n",
        "        solution[index] = random.randint(0, 7)\n",
        "\n",
        "def evolve(population, mutation_rate):\n",
        "    fitness_scores = [fitness(solution) for solution in population]\n",
        "    new_population = []\n",
        "\n",
        "    for _ in range(len(population) // 2):\n",
        "        parent1, parent2 = selection(population, fitness_scores)\n",
        "        child1 = crossover(parent1, parent2)\n",
        "        child2 = crossover(parent2, parent1)\n",
        "        mutate(child1, mutation_rate)\n",
        "        mutate(child2, mutation_rate)\n",
        "        new_population.extend([child1, child2])\n",
        "\n",
        "    return new_population\n",
        "\n",
        "def solve(population_size=100, mutation_rate=0.01, max_generations=1000):\n",
        "    population = initial_population(population_size, specific_solution=[3, 2, 7, 5, 2, 4, 1, 1])\n",
        "    for generation in range(max_generations):\n",
        "        fitness_scores = [fitness(solution) for solution in population]\n",
        "        best_solution = max(population, key=fitness)\n",
        "        if fitness(best_solution) == 28:\n",
        "            print(\"Solution found in generation\", generation)\n",
        "            return best_solution\n",
        "        print(\"Generation:\", generation, \"Best Fitness:\", fitness(best_solution))\n",
        "        print(\"Best Solution:\", best_solution)\n",
        "        population = evolve(population, mutation_rate)\n",
        "\n",
        "    print(\"No solution found after\", max_generations, \"generations.\")\n",
        "    return None\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    solution = solve()\n",
        "    if solution:\n",
        "        print(\"Solution:\", solution)\n",
        "    else:\n",
        "        print(\"No solution found.\")\n"
      ],
      "metadata": {
        "id": "a_wRhEEc60yc",
        "outputId": "b5fad879-977b-4c85-b723-fa246ac86198",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation: 0 Best Fitness: 25\n",
            "Best Solution: [6, 0, 3, 4, 7, 5, 3, 5]\n",
            "Generation: 1 Best Fitness: 25\n",
            "Best Solution: [2, 5, 3, 7, 0, 2, 6, 4]\n",
            "Generation: 2 Best Fitness: 25\n",
            "Best Solution: [2, 7, 5, 1, 1, 3, 0, 6]\n",
            "Generation: 3 Best Fitness: 25\n",
            "Best Solution: [5, 5, 1, 7, 0, 2, 6, 4]\n",
            "Generation: 4 Best Fitness: 26\n",
            "Best Solution: [2, 3, 6, 4, 7, 5, 0, 2]\n",
            "Generation: 5 Best Fitness: 25\n",
            "Best Solution: [2, 6, 3, 0, 5, 3, 0, 7]\n",
            "Generation: 6 Best Fitness: 25\n",
            "Best Solution: [4, 1, 5, 0, 5, 3, 0, 7]\n",
            "Generation: 7 Best Fitness: 25\n",
            "Best Solution: [6, 4, 1, 7, 0, 2, 0, 7]\n",
            "Generation: 8 Best Fitness: 26\n",
            "Best Solution: [2, 3, 1, 7, 4, 0, 0, 5]\n",
            "Generation: 9 Best Fitness: 24\n",
            "Best Solution: [1, 1, 2, 6, 7, 2, 0, 5]\n",
            "Generation: 10 Best Fitness: 26\n",
            "Best Solution: [2, 3, 1, 7, 4, 2, 0, 5]\n",
            "Generation: 11 Best Fitness: 25\n",
            "Best Solution: [2, 3, 6, 4, 7, 5, 3, 5]\n",
            "Generation: 12 Best Fitness: 25\n",
            "Best Solution: [2, 1, 6, 4, 7, 5, 3, 5]\n",
            "Generation: 13 Best Fitness: 25\n",
            "Best Solution: [2, 7, 5, 4, 0, 4, 6, 1]\n",
            "Generation: 14 Best Fitness: 26\n",
            "Best Solution: [2, 3, 1, 6, 4, 6, 0, 5]\n",
            "Generation: 15 Best Fitness: 26\n",
            "Best Solution: [2, 3, 1, 7, 4, 0, 0, 5]\n",
            "Generation: 16 Best Fitness: 26\n",
            "Best Solution: [2, 3, 1, 7, 4, 0, 0, 5]\n",
            "Generation: 17 Best Fitness: 26\n",
            "Best Solution: [2, 3, 1, 7, 4, 0, 0, 5]\n",
            "Generation: 18 Best Fitness: 26\n",
            "Best Solution: [6, 3, 1, 7, 7, 2, 0, 5]\n",
            "Generation: 19 Best Fitness: 26\n",
            "Best Solution: [6, 3, 1, 7, 4, 0, 0, 5]\n",
            "Generation: 20 Best Fitness: 26\n",
            "Best Solution: [2, 3, 1, 7, 4, 0, 0, 5]\n",
            "Generation: 21 Best Fitness: 27\n",
            "Best Solution: [0, 3, 1, 4, 7, 0, 2, 5]\n",
            "Generation: 22 Best Fitness: 26\n",
            "Best Solution: [2, 3, 1, 4, 7, 0, 2, 5]\n",
            "Generation: 23 Best Fitness: 26\n",
            "Best Solution: [2, 7, 1, 4, 0, 6, 0, 5]\n",
            "Generation: 24 Best Fitness: 26\n",
            "Best Solution: [2, 3, 1, 7, 4, 0, 0, 5]\n",
            "Generation: 25 Best Fitness: 26\n",
            "Best Solution: [0, 7, 1, 7, 0, 6, 3, 5]\n",
            "Generation: 26 Best Fitness: 26\n",
            "Best Solution: [2, 3, 1, 7, 4, 0, 0, 5]\n",
            "Generation: 27 Best Fitness: 26\n",
            "Best Solution: [2, 7, 1, 7, 0, 6, 0, 5]\n",
            "Generation: 28 Best Fitness: 26\n",
            "Best Solution: [2, 3, 1, 7, 4, 0, 0, 5]\n",
            "Generation: 29 Best Fitness: 26\n",
            "Best Solution: [2, 3, 1, 7, 4, 0, 3, 5]\n",
            "Generation: 30 Best Fitness: 26\n",
            "Best Solution: [2, 7, 1, 7, 0, 6, 0, 5]\n",
            "Generation: 31 Best Fitness: 27\n",
            "Best Solution: [6, 2, 1, 7, 4, 0, 3, 5]\n",
            "Generation: 32 Best Fitness: 26\n",
            "Best Solution: [6, 3, 1, 7, 4, 0, 0, 5]\n",
            "Generation: 33 Best Fitness: 26\n",
            "Best Solution: [2, 3, 1, 7, 4, 0, 0, 5]\n",
            "Generation: 34 Best Fitness: 27\n",
            "Best Solution: [2, 3, 1, 7, 4, 6, 0, 5]\n",
            "Generation: 35 Best Fitness: 27\n",
            "Best Solution: [2, 3, 1, 7, 4, 6, 0, 5]\n",
            "Generation: 36 Best Fitness: 27\n",
            "Best Solution: [2, 0, 1, 7, 4, 6, 3, 5]\n",
            "Generation: 37 Best Fitness: 26\n",
            "Best Solution: [2, 3, 1, 7, 4, 0, 0, 5]\n",
            "Generation: 38 Best Fitness: 27\n",
            "Best Solution: [2, 3, 1, 7, 4, 6, 0, 5]\n",
            "Generation: 39 Best Fitness: 27\n",
            "Best Solution: [2, 3, 1, 7, 4, 6, 0, 5]\n",
            "Generation: 40 Best Fitness: 27\n",
            "Best Solution: [2, 3, 1, 7, 4, 6, 0, 5]\n",
            "Generation: 41 Best Fitness: 27\n",
            "Best Solution: [2, 3, 1, 7, 4, 6, 0, 5]\n",
            "Generation: 42 Best Fitness: 27\n",
            "Best Solution: [2, 0, 1, 7, 4, 6, 3, 5]\n",
            "Generation: 43 Best Fitness: 27\n",
            "Best Solution: [2, 6, 1, 7, 4, 6, 0, 5]\n",
            "Generation: 44 Best Fitness: 26\n",
            "Best Solution: [2, 3, 1, 7, 4, 0, 0, 5]\n",
            "Generation: 45 Best Fitness: 27\n",
            "Best Solution: [2, 3, 1, 7, 4, 6, 0, 5]\n",
            "Generation: 46 Best Fitness: 27\n",
            "Best Solution: [2, 3, 1, 7, 4, 6, 0, 5]\n",
            "Generation: 47 Best Fitness: 27\n",
            "Best Solution: [6, 3, 1, 7, 4, 0, 3, 5]\n",
            "Generation: 48 Best Fitness: 27\n",
            "Best Solution: [2, 0, 1, 7, 4, 6, 3, 5]\n",
            "Generation: 49 Best Fitness: 27\n",
            "Best Solution: [2, 0, 1, 7, 4, 6, 3, 5]\n",
            "Generation: 50 Best Fitness: 27\n",
            "Best Solution: [2, 3, 1, 7, 4, 6, 0, 5]\n",
            "Generation: 51 Best Fitness: 27\n",
            "Best Solution: [2, 6, 1, 7, 4, 6, 0, 5]\n",
            "Generation: 52 Best Fitness: 27\n",
            "Best Solution: [2, 3, 1, 7, 4, 6, 0, 5]\n",
            "Solution found in generation 53\n",
            "Solution: [2, 6, 1, 7, 4, 0, 3, 5]\n"
          ]
        }
      ]
    }
  ]
}